print("=== Cross-Validation Accuracy ===")
print(f"Model A (Original Features): {scores_A.mean():.4f} ± {scores_A.std():.4f}")
print(f"Model B (Original + Rolling Features): {scores_B.mean():.4f} ± {scores_B.std():.4f}")

# =====================================================
# 3️⃣ Learning Curve visualization
# =====================================================
def plot_learning_curve(model, X, y, title):
    train_sizes, train_scores, test_scores = learning_curve(
        model, X, y, cv=cv, scoring='accuracy',
        train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1
    )

    # Compute mean and std
    train_mean = np.mean(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_std = np.std(test_scores, axis=1)

    # Plot
    plt.figure(figsize=(8,6))
    plt.title(title)
    plt.plot(train_sizes, train_mean, label='Training score', marker='o')
    plt.plot(train_sizes, test_mean, label='Validation score', marker='s')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2)
    plt.xlabel('Training Set Size')
    plt.ylabel('Accuracy')
    plt.legend(loc='best')
    plt.grid(True)