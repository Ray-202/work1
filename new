import pandas as pd
import numpy as np
from sklearn.model_selection import GroupShuffleSplit
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# =====================================================
# 1️⃣ Load your data
# =====================================================
# data = pd.read_csv("your_data.csv")  # Uncomment and load your file here

# Make sure 'Type' (target) and 'Object' (group id) exist
assert 'Type' in data.columns, "Target column 'Type' not found"
assert 'Object' in data.columns, "Group column 'Object' not found"

# =====================================================
# 2️⃣ Select features
# =====================================================
selected_features = ['feature1', 'feature2', 'feature3']  # <-- Replace with your actual features

# Drop any label-like columns from features
X = data[selected_features + ['Object']]
y = data['Type']

# =====================================================
# 3️⃣ Group-based Train/Test Split (to avoid leakage)
# =====================================================
splitter = GroupShuffleSplit(test_size=0.3, n_splits=1, random_state=42)
train_idx, test_idx = next(splitter.split(X, groups=X['Object']))

train = data.iloc[train_idx].copy()
test = data.iloc[test_idx].copy()

print(f"Train objects: {train['Object'].nunique()}, Test objects: {test['Object'].nunique()}")

# =====================================================
# 4️⃣ Compute rolling features WITHIN each object
# =====================================================
def add_rolling_features(df, features, window=5):
    df = df.copy()
    for f in features:
        df[f'{f}_roll_mean'] = df[f].rolling(window=window, min_periods=1).mean()
        df[f'{f}_roll_std'] = df[f].rolling(window=window, min_periods=1).std().fillna(0)
    return df

train = train.groupby('Object', group_keys=False).apply(
    lambda x: add_rolling_features(x, selected_features, window=5)
)
test = test.groupby('Object', group_keys=False).apply(
    lambda x: add_rolling_features(x, selected_features, window=5)
)

# Check rolling features
print("\nSample of computed rolling features:")
print(train[[f for f in train.columns if 'roll' in f]].head(10))

# =====================================================
# 5️⃣ Define datasets for both models
# =====================================================
X_train_A = train[selected_features]
X_test_A = test[selected_features]

X_train_B = train[selected_features + [f"{f}_roll_mean" for f in selected_features] + [f"{f}_roll_std" for f in selected_features]]
X_test_B = test[selected_features + [f"{f}_roll_mean" for f in selected_features] + [f"{f}_roll_std" for f in selected_features]]

y_train = train['Type']
y_test = test['Type']

# =====================================================
# 6️⃣ Train Model A (original features)
# =====================================================
model_A = GaussianNB()
model_A.fit(X_train_A, y_train)
y_pred_A = model_A.predict(X_test_A)

print("\n=== Model A: Original Features ===")
print("Accuracy:", accuracy_score(y_test, y_pred_A))
print(classification_report(y_test, y_pred_A))

# =====================================================
# 7️⃣ Train Model B (original + rolling features)
# =====================================================
model_B = GaussianNB()
model_B.fit(X_train_B, y_train)
y_pred_B = model_B.predict(X_test_B)

print("\n=== Model B: Original + Rolling Features ===")
print("Accuracy:", accuracy_score(y_test, y_pred_B))
print(classification_report(y_test, y_pred_B))

# =====================================================
# 8️⃣ Visualize confusion matrices
# =====================================================
fig, ax = plt.subplots(1, 2, figsize=(14, 5))

sns.heatmap(confusion_matrix(y_test, y_pred_A), annot=True, fmt="d", ax=ax[0])
ax[0].set_title("Original Features")

sns.heatmap(confusion_matrix(y_test, y_pred_B), annot=True, fmt="d", ax=ax[1])
ax[1].set_title("Original + Rolling Features")

plt.show()